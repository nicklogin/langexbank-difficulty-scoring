{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"realec_errors_sample.xlsx\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(\"realec_errors_050821_keep_all.xlsx\",\n",
    "                    engine='openpyxl', index_col='Unnamed: 0')\n",
    "#df2 = df2[df2['Folder'].str.contains('exam')]\n",
    "#df2 = df2.drop_duplicates(subset=['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Right answer</th>\n",
       "      <th>Error type</th>\n",
       "      <th>Corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51175</td>\n",
       "      <td>Actually, it is an old tradition of &lt;b&gt;distri...</td>\n",
       "      <td>spreading</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>Actually, it is an old tradition of spreading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36478</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "      <td>the world's investment</td>\n",
       "      <td>Articles</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6697</td>\n",
       "      <td>Now, letвЂ™s take a look &lt;b&gt;on&lt;/b&gt; the situat...</td>\n",
       "      <td>at</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>Now, letвЂ™s take a look at the situation in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76371</td>\n",
       "      <td>Here we can see five lines which &lt;b&gt;shows&lt;/b&gt;...</td>\n",
       "      <td>show</td>\n",
       "      <td>Tense_choice</td>\n",
       "      <td>Here we can see five lines which show us how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67749</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "      <td>this money</td>\n",
       "      <td>Countable_uncountable</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           Sentence  \\\n",
       "0  51175   Actually, it is an old tradition of <b>distri...   \n",
       "1  36478  The graph given to us represents the informati...   \n",
       "2   6697   Now, letвЂ™s take a look <b>on</b> the situat...   \n",
       "3  76371   Here we can see five lines which <b>shows</b>...   \n",
       "4  67749   Moreover, they need money to feed their child...   \n",
       "\n",
       "             Right answer             Error type  \\\n",
       "0               spreading        lex_item_choice   \n",
       "1  the world's investment               Articles   \n",
       "2                      at           Prepositions   \n",
       "3                    show           Tense_choice   \n",
       "4              this money  Countable_uncountable   \n",
       "\n",
       "                                           Corrected  \n",
       "0   Actually, it is an old tradition of spreading...  \n",
       "1  The graph given to us represents the informati...  \n",
       "2   Now, letвЂ™s take a look at the situation in ...  \n",
       "3   Here we can see five lines which show us how ...  \n",
       "4   Moreover, they need money to feed their child...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               int64\n",
       "Sentence        object\n",
       "Right answer    object\n",
       "Error type      object\n",
       "Corrected       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence        object\n",
       "Right answer    object\n",
       "Error type      object\n",
       "Folder          object\n",
       "Filename        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Right answer</th>\n",
       "      <th>Error type</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It could be clearly seen from the graph that ...</td>\n",
       "      <td>other</td>\n",
       "      <td>suggestion</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It could be clearly seen from the graph that ...</td>\n",
       "      <td>websites</td>\n",
       "      <td>Spelling</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moreover, a considerable prevalence of young ...</td>\n",
       "      <td>has to be</td>\n",
       "      <td>Modals</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obviously, there is a dramatic gap between th...</td>\n",
       "      <td>the former</td>\n",
       "      <td>Ref_device</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obviously, there is a dramatic gap between th...</td>\n",
       "      <td>is popular with</td>\n",
       "      <td>Word_choice</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence     Right answer  \\\n",
       "0   It could be clearly seen from the graph that ...            other   \n",
       "1   It could be clearly seen from the graph that ...         websites   \n",
       "2   Moreover, a considerable prevalence of young ...        has to be   \n",
       "3   Obviously, there is a dramatic gap between th...       the former   \n",
       "4   Obviously, there is a dramatic gap between th...  is popular with   \n",
       "\n",
       "    Error type                                             Folder  \\\n",
       "0   suggestion  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "1     Spelling  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "2       Modals  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "3   Ref_device  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "4  Word_choice  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "\n",
       "         Filename  \n",
       "0  2017_EGe_121_1  \n",
       "1  2017_EGe_121_1  \n",
       "2  2017_EGe_121_1  \n",
       "3  2017_EGe_121_1  \n",
       "4  2017_EGe_121_1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2], join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Right answer</th>\n",
       "      <th>Error type</th>\n",
       "      <th>Corrected</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Right answer</th>\n",
       "      <th>Error type</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51175</td>\n",
       "      <td>Actually, it is an old tradition of &lt;b&gt;distri...</td>\n",
       "      <td>spreading</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>Actually, it is an old tradition of spreading...</td>\n",
       "      <td>It could be clearly seen from the graph that ...</td>\n",
       "      <td>other</td>\n",
       "      <td>suggestion</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36478</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "      <td>the world's investment</td>\n",
       "      <td>Articles</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "      <td>It could be clearly seen from the graph that ...</td>\n",
       "      <td>websites</td>\n",
       "      <td>Spelling</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6697</td>\n",
       "      <td>Now, letвЂ™s take a look &lt;b&gt;on&lt;/b&gt; the situat...</td>\n",
       "      <td>at</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>Now, letвЂ™s take a look at the situation in ...</td>\n",
       "      <td>Moreover, a considerable prevalence of young ...</td>\n",
       "      <td>has to be</td>\n",
       "      <td>Modals</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76371</td>\n",
       "      <td>Here we can see five lines which &lt;b&gt;shows&lt;/b&gt;...</td>\n",
       "      <td>show</td>\n",
       "      <td>Tense_choice</td>\n",
       "      <td>Here we can see five lines which show us how ...</td>\n",
       "      <td>Obviously, there is a dramatic gap between th...</td>\n",
       "      <td>the former</td>\n",
       "      <td>Ref_device</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67749</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "      <td>this money</td>\n",
       "      <td>Countable_uncountable</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "      <td>Obviously, there is a dramatic gap between th...</td>\n",
       "      <td>is popular with</td>\n",
       "      <td>Word_choice</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_121_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>33536</td>\n",
       "      <td>The &lt;b&gt;project&lt;/b&gt; is to create an automated v...</td>\n",
       "      <td>objective of the course project</td>\n",
       "      <td>Discourse</td>\n",
       "      <td>The objective of the course project is to crea...</td>\n",
       "      <td>It will not be appropriate for university wor...</td>\n",
       "      <td>which</td>\n",
       "      <td>Relative_clause</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2014_AAl_2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>68578</td>\n",
       "      <td>A more detailed look reveals that there are s...</td>\n",
       "      <td>exceptions to</td>\n",
       "      <td>suggestion</td>\n",
       "      <td>A more detailed look reveals that there are s...</td>\n",
       "      <td>It will not be appropriate for university wor...</td>\n",
       "      <td>every person may have</td>\n",
       "      <td>Word_order</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2014_AAl_2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>80835</td>\n",
       "      <td>Firstly, I believe that space could &lt;b&gt;wait&lt;/...</td>\n",
       "      <td>wait for</td>\n",
       "      <td>Spelling</td>\n",
       "      <td>Firstly, I believe that space could wait for ...</td>\n",
       "      <td>There &lt;b&gt;is&lt;/b&gt; the circular graphs: the first...</td>\n",
       "      <td>are</td>\n",
       "      <td>Agreement_errors</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_OBy_43_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>67232</td>\n",
       "      <td>&lt;b&gt;Having paid&lt;/b&gt; more attention to it we wi...</td>\n",
       "      <td>By paying</td>\n",
       "      <td>Voice</td>\n",
       "      <td>By paying more attention to it we will decrea...</td>\n",
       "      <td>There are the circular graphs: the first one &lt;...</td>\n",
       "      <td>shows</td>\n",
       "      <td>Agreement_errors</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_OBy_43_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>36905</td>\n",
       "      <td>It is more comfortable of course when your fr...</td>\n",
       "      <td>at</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>It is more comfortable of course when your fr...</td>\n",
       "      <td>There are the circular graphs: the first one s...</td>\n",
       "      <td>the information</td>\n",
       "      <td>Articles</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_OBy_43_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           Sentence  \\\n",
       "0    51175   Actually, it is an old tradition of <b>distri...   \n",
       "1    36478  The graph given to us represents the informati...   \n",
       "2     6697   Now, letвЂ™s take a look <b>on</b> the situat...   \n",
       "3    76371   Here we can see five lines which <b>shows</b>...   \n",
       "4    67749   Moreover, they need money to feed their child...   \n",
       "..     ...                                                ...   \n",
       "995  33536  The <b>project</b> is to create an automated v...   \n",
       "996  68578   A more detailed look reveals that there are s...   \n",
       "997  80835   Firstly, I believe that space could <b>wait</...   \n",
       "998  67232   <b>Having paid</b> more attention to it we wi...   \n",
       "999  36905   It is more comfortable of course when your fr...   \n",
       "\n",
       "                        Right answer             Error type  \\\n",
       "0                          spreading        lex_item_choice   \n",
       "1             the world's investment               Articles   \n",
       "2                                 at           Prepositions   \n",
       "3                               show           Tense_choice   \n",
       "4                         this money  Countable_uncountable   \n",
       "..                               ...                    ...   \n",
       "995  objective of the course project              Discourse   \n",
       "996                    exceptions to             suggestion   \n",
       "997                         wait for               Spelling   \n",
       "998                        By paying                  Voice   \n",
       "999                               at           Prepositions   \n",
       "\n",
       "                                             Corrected  \\\n",
       "0     Actually, it is an old tradition of spreading...   \n",
       "1    The graph given to us represents the informati...   \n",
       "2     Now, letвЂ™s take a look at the situation in ...   \n",
       "3     Here we can see five lines which show us how ...   \n",
       "4     Moreover, they need money to feed their child...   \n",
       "..                                                 ...   \n",
       "995  The objective of the course project is to crea...   \n",
       "996   A more detailed look reveals that there are s...   \n",
       "997   Firstly, I believe that space could wait for ...   \n",
       "998   By paying more attention to it we will decrea...   \n",
       "999   It is more comfortable of course when your fr...   \n",
       "\n",
       "                                              Sentence           Right answer  \\\n",
       "0     It could be clearly seen from the graph that ...                  other   \n",
       "1     It could be clearly seen from the graph that ...               websites   \n",
       "2     Moreover, a considerable prevalence of young ...              has to be   \n",
       "3     Obviously, there is a dramatic gap between th...             the former   \n",
       "4     Obviously, there is a dramatic gap between th...        is popular with   \n",
       "..                                                 ...                    ...   \n",
       "995   It will not be appropriate for university wor...                  which   \n",
       "996   It will not be appropriate for university wor...  every person may have   \n",
       "997  There <b>is</b> the circular graphs: the first...                    are   \n",
       "998  There are the circular graphs: the first one <...                  shows   \n",
       "999  There are the circular graphs: the first one s...        the information   \n",
       "\n",
       "           Error type                                             Folder  \\\n",
       "0          suggestion  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "1            Spelling  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "2              Modals  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "3          Ref_device  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "4         Word_choice  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "..                ...                                                ...   \n",
       "995   Relative_clause  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "996        Word_order  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "997  Agreement_errors  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "998  Agreement_errors  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "999          Articles  downloaded_2021_08_05_15_05_02099641/data/exam...   \n",
       "\n",
       "           Filename  \n",
       "0    2017_EGe_121_1  \n",
       "1    2017_EGe_121_1  \n",
       "2    2017_EGe_121_1  \n",
       "3    2017_EGe_121_1  \n",
       "4    2017_EGe_121_1  \n",
       "..              ...  \n",
       "995    2014_AAl_2_2  \n",
       "996    2014_AAl_2_2  \n",
       "997   2017_OBy_43_1  \n",
       "998   2017_OBy_43_1  \n",
       "999   2017_OBy_43_1  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индекс предложения в выдаче не всегда сходится, потому что в корпусе стало больше текстов - надо склеивать по тексту предложения (Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df1.merge(df2, on='Sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Right answer_x</th>\n",
       "      <th>Error type_x</th>\n",
       "      <th>Corrected</th>\n",
       "      <th>Right answer_y</th>\n",
       "      <th>Error type_y</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51175</td>\n",
       "      <td>Actually, it is an old tradition of &lt;b&gt;distri...</td>\n",
       "      <td>spreading</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>Actually, it is an old tradition of spreading...</td>\n",
       "      <td>spreading</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_ABl_48_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36478</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "      <td>the world's investment</td>\n",
       "      <td>Articles</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "      <td>the world's investment</td>\n",
       "      <td>Articles</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2016_JSl_148_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67749</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "      <td>this money</td>\n",
       "      <td>Countable_uncountable</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "      <td>this money</td>\n",
       "      <td>Countable_uncountable</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_113_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30127</td>\n",
       "      <td>It is noticable that the figures in males &lt;b&gt;...</td>\n",
       "      <td>who owned</td>\n",
       "      <td>Absence_comp_sent</td>\n",
       "      <td>It is noticable that the figures in males who...</td>\n",
       "      <td>who owned</td>\n",
       "      <td>Verbs</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/old_...</td>\n",
       "      <td>ESha_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4238</td>\n",
       "      <td>Globalization creates an important basis for ...</td>\n",
       "      <td>,</td>\n",
       "      <td>Derivation</td>\n",
       "      <td>Globalization creates an important basis for ...</td>\n",
       "      <td>,</td>\n",
       "      <td>Punctuation</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/2012...</td>\n",
       "      <td>esl_01275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>33536</td>\n",
       "      <td>The &lt;b&gt;project&lt;/b&gt; is to create an automated v...</td>\n",
       "      <td>objective of the course project</td>\n",
       "      <td>Discourse</td>\n",
       "      <td>The objective of the course project is to crea...</td>\n",
       "      <td>objective of the course project</td>\n",
       "      <td>Discourse</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/2012...</td>\n",
       "      <td>esl_00372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>68578</td>\n",
       "      <td>A more detailed look reveals that there are s...</td>\n",
       "      <td>exceptions to</td>\n",
       "      <td>suggestion</td>\n",
       "      <td>A more detailed look reveals that there are s...</td>\n",
       "      <td>exceptions to</td>\n",
       "      <td>suggestion</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_167_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>80835</td>\n",
       "      <td>Firstly, I believe that space could &lt;b&gt;wait&lt;/...</td>\n",
       "      <td>wait for</td>\n",
       "      <td>Spelling</td>\n",
       "      <td>Firstly, I believe that space could wait for ...</td>\n",
       "      <td>wait for</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_203_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>67232</td>\n",
       "      <td>&lt;b&gt;Having paid&lt;/b&gt; more attention to it we wi...</td>\n",
       "      <td>By paying</td>\n",
       "      <td>Voice</td>\n",
       "      <td>By paying more attention to it we will decrea...</td>\n",
       "      <td>By paying</td>\n",
       "      <td>Participial_constr</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_86_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>36905</td>\n",
       "      <td>It is more comfortable of course when your fr...</td>\n",
       "      <td>at</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>It is more comfortable of course when your fr...</td>\n",
       "      <td>at</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/2012...</td>\n",
       "      <td>esl_00433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           Sentence  \\\n",
       "0     51175   Actually, it is an old tradition of <b>distri...   \n",
       "1     36478  The graph given to us represents the informati...   \n",
       "2     67749   Moreover, they need money to feed their child...   \n",
       "3     30127   It is noticable that the figures in males <b>...   \n",
       "4      4238   Globalization creates an important basis for ...   \n",
       "...     ...                                                ...   \n",
       "1129  33536  The <b>project</b> is to create an automated v...   \n",
       "1130  68578   A more detailed look reveals that there are s...   \n",
       "1131  80835   Firstly, I believe that space could <b>wait</...   \n",
       "1132  67232   <b>Having paid</b> more attention to it we wi...   \n",
       "1133  36905   It is more comfortable of course when your fr...   \n",
       "\n",
       "                       Right answer_x           Error type_x  \\\n",
       "0                           spreading        lex_item_choice   \n",
       "1              the world's investment               Articles   \n",
       "2                          this money  Countable_uncountable   \n",
       "3                           who owned      Absence_comp_sent   \n",
       "4                                   ,             Derivation   \n",
       "...                               ...                    ...   \n",
       "1129  objective of the course project              Discourse   \n",
       "1130                    exceptions to             suggestion   \n",
       "1131                         wait for               Spelling   \n",
       "1132                        By paying                  Voice   \n",
       "1133                               at           Prepositions   \n",
       "\n",
       "                                              Corrected  \\\n",
       "0      Actually, it is an old tradition of spreading...   \n",
       "1     The graph given to us represents the informati...   \n",
       "2      Moreover, they need money to feed their child...   \n",
       "3      It is noticable that the figures in males who...   \n",
       "4      Globalization creates an important basis for ...   \n",
       "...                                                 ...   \n",
       "1129  The objective of the course project is to crea...   \n",
       "1130   A more detailed look reveals that there are s...   \n",
       "1131   Firstly, I believe that space could wait for ...   \n",
       "1132   By paying more attention to it we will decrea...   \n",
       "1133   It is more comfortable of course when your fr...   \n",
       "\n",
       "                       Right answer_y           Error type_y  \\\n",
       "0                           spreading        lex_item_choice   \n",
       "1              the world's investment               Articles   \n",
       "2                          this money  Countable_uncountable   \n",
       "3                           who owned                  Verbs   \n",
       "4                                   ,            Punctuation   \n",
       "...                               ...                    ...   \n",
       "1129  objective of the course project              Discourse   \n",
       "1130                    exceptions to             suggestion   \n",
       "1131                         wait for           Prepositions   \n",
       "1132                        By paying     Participial_constr   \n",
       "1133                               at           Prepositions   \n",
       "\n",
       "                                                 Folder        Filename  \n",
       "0     downloaded_2021_08_05_15_05_02099641/data/exam...   2017_ABl_48_2  \n",
       "1     downloaded_2021_08_05_15_05_02099641/data/exam...  2016_JSl_148_1  \n",
       "2     downloaded_2021_08_05_15_05_02099641/data/exam...  2017_EGe_113_2  \n",
       "3     downloaded_2021_08_05_15_05_02099641/data/old_...        ESha_2_1  \n",
       "4     downloaded_2021_08_05_15_05_02099641/data/2012...       esl_01275  \n",
       "...                                                 ...             ...  \n",
       "1129  downloaded_2021_08_05_15_05_02099641/data/2012...       esl_00372  \n",
       "1130  downloaded_2021_08_05_15_05_02099641/data/exam...  2017_EGe_167_1  \n",
       "1131  downloaded_2021_08_05_15_05_02099641/data/exam...  2017_EGe_203_2  \n",
       "1132  downloaded_2021_08_05_15_05_02099641/data/exam...   2017_EGe_86_2  \n",
       "1133  downloaded_2021_08_05_15_05_02099641/data/2012...       esl_00433  \n",
       "\n",
       "[1134 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Corrected',\n",
       " 'Error type_x',\n",
       " 'Error type_y',\n",
       " 'Filename',\n",
       " 'Right answer_x',\n",
       " 'Right answer_y',\n",
       " 'Sentence'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_concat.columns) - {'Folder','id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method drop_duplicates in module pandas.core.frame:\n",
      "\n",
      "drop_duplicates(subset: Union[Hashable, Sequence[Hashable], NoneType] = None, keep: Union[str, bool] = 'first', inplace: bool = False, ignore_index: bool = False) -> Union[ForwardRef('DataFrame'), NoneType] method of pandas.core.frame.DataFrame instance\n",
      "    Return DataFrame with duplicate rows removed.\n",
      "    \n",
      "    Considering certain columns is optional. Indexes, including time indexes\n",
      "    are ignored.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    subset : column label or sequence of labels, optional\n",
      "        Only consider certain columns for identifying duplicates, by\n",
      "        default use all of the columns.\n",
      "    keep : {'first', 'last', False}, default 'first'\n",
      "        Determines which duplicates (if any) to keep.\n",
      "        - ``first`` : Drop duplicates except for the first occurrence.\n",
      "        - ``last`` : Drop duplicates except for the last occurrence.\n",
      "        - False : Drop all duplicates.\n",
      "    inplace : bool, default False\n",
      "        Whether to drop duplicates in place or to return a copy.\n",
      "    ignore_index : bool, default False\n",
      "        If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      "    \n",
      "        .. versionadded:: 1.0.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        DataFrame with duplicates removed or None if ``inplace=True``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.value_counts: Count unique combinations of columns.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Consider dataset containing ramen rating.\n",
      "    \n",
      "    >>> df = pd.DataFrame({\n",
      "    ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      "    ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      "    ...     'rating': [4, 4, 3.5, 15, 5]\n",
      "    ... })\n",
      "    >>> df\n",
      "        brand style  rating\n",
      "    0  Yum Yum   cup     4.0\n",
      "    1  Yum Yum   cup     4.0\n",
      "    2  Indomie   cup     3.5\n",
      "    3  Indomie  pack    15.0\n",
      "    4  Indomie  pack     5.0\n",
      "    \n",
      "    By default, it removes duplicate rows based on all columns.\n",
      "    \n",
      "    >>> df.drop_duplicates()\n",
      "        brand style  rating\n",
      "    0  Yum Yum   cup     4.0\n",
      "    2  Indomie   cup     3.5\n",
      "    3  Indomie  pack    15.0\n",
      "    4  Indomie  pack     5.0\n",
      "    \n",
      "    To remove duplicates on specific column(s), use ``subset``.\n",
      "    \n",
      "    >>> df.drop_duplicates(subset=['brand'])\n",
      "        brand style  rating\n",
      "    0  Yum Yum   cup     4.0\n",
      "    2  Indomie   cup     3.5\n",
      "    \n",
      "    To remove duplicates and keep last occurences, use ``keep``.\n",
      "    \n",
      "    >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
      "        brand style  rating\n",
      "    1  Yum Yum   cup     4.0\n",
      "    2  Indomie   cup     3.5\n",
      "    4  Indomie  pack     5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df_concat.drop_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_concat = df_concat.drop_duplicates(subset=list(set(df_concat.columns)-{'Folder','Filename'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\k1l77\\desktop\\182e~1\\term_p~1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "exam_values = df_concat[df_concat['Folder'].str.contains('exam')]['Sentence'].unique()\n",
    "df_concat['Есть дубликат в exam'] = df_concat.apply(lambda x: 'exam' not in x['Folder'] and\\\n",
    "                                                   x['Sentence'] in exam_values,\n",
    "                                                   axis=1)\n",
    "df_concat = df_concat[df_concat['Есть дубликат в exam'] == False]\n",
    "\n",
    "sent_counts = df_concat['Sentence'].value_counts()\n",
    "df_concat['Есть дубликат'] = df_concat['Sentence'].apply(lambda x: sent_counts[x] > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Right answer_x</th>\n",
       "      <th>Error type_x</th>\n",
       "      <th>Corrected</th>\n",
       "      <th>Right answer_y</th>\n",
       "      <th>Error type_y</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Есть дубликат в exam</th>\n",
       "      <th>Есть дубликат</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51175</td>\n",
       "      <td>Actually, it is an old tradition of &lt;b&gt;distri...</td>\n",
       "      <td>spreading</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>Actually, it is an old tradition of spreading...</td>\n",
       "      <td>spreading</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_ABl_48_2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36478</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "      <td>the world's investment</td>\n",
       "      <td>Articles</td>\n",
       "      <td>The graph given to us represents the informati...</td>\n",
       "      <td>the world's investment</td>\n",
       "      <td>Articles</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2016_JSl_148_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67749</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "      <td>this money</td>\n",
       "      <td>Countable_uncountable</td>\n",
       "      <td>Moreover, they need money to feed their child...</td>\n",
       "      <td>this money</td>\n",
       "      <td>Countable_uncountable</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_113_2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30127</td>\n",
       "      <td>It is noticable that the figures in males &lt;b&gt;...</td>\n",
       "      <td>who owned</td>\n",
       "      <td>Absence_comp_sent</td>\n",
       "      <td>It is noticable that the figures in males who...</td>\n",
       "      <td>who owned</td>\n",
       "      <td>Verbs</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/old_...</td>\n",
       "      <td>ESha_2_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4238</td>\n",
       "      <td>Globalization creates an important basis for ...</td>\n",
       "      <td>,</td>\n",
       "      <td>Derivation</td>\n",
       "      <td>Globalization creates an important basis for ...</td>\n",
       "      <td>,</td>\n",
       "      <td>Punctuation</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/2012...</td>\n",
       "      <td>esl_01275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>33536</td>\n",
       "      <td>The &lt;b&gt;project&lt;/b&gt; is to create an automated v...</td>\n",
       "      <td>objective of the course project</td>\n",
       "      <td>Discourse</td>\n",
       "      <td>The objective of the course project is to crea...</td>\n",
       "      <td>objective of the course project</td>\n",
       "      <td>Discourse</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/2012...</td>\n",
       "      <td>esl_00372</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>68578</td>\n",
       "      <td>A more detailed look reveals that there are s...</td>\n",
       "      <td>exceptions to</td>\n",
       "      <td>suggestion</td>\n",
       "      <td>A more detailed look reveals that there are s...</td>\n",
       "      <td>exceptions to</td>\n",
       "      <td>suggestion</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_167_1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>80835</td>\n",
       "      <td>Firstly, I believe that space could &lt;b&gt;wait&lt;/...</td>\n",
       "      <td>wait for</td>\n",
       "      <td>Spelling</td>\n",
       "      <td>Firstly, I believe that space could wait for ...</td>\n",
       "      <td>wait for</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_203_2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>67232</td>\n",
       "      <td>&lt;b&gt;Having paid&lt;/b&gt; more attention to it we wi...</td>\n",
       "      <td>By paying</td>\n",
       "      <td>Voice</td>\n",
       "      <td>By paying more attention to it we will decrea...</td>\n",
       "      <td>By paying</td>\n",
       "      <td>Participial_constr</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/exam...</td>\n",
       "      <td>2017_EGe_86_2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>36905</td>\n",
       "      <td>It is more comfortable of course when your fr...</td>\n",
       "      <td>at</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>It is more comfortable of course when your fr...</td>\n",
       "      <td>at</td>\n",
       "      <td>Prepositions</td>\n",
       "      <td>downloaded_2021_08_05_15_05_02099641/data/2012...</td>\n",
       "      <td>esl_00433</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>844 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           Sentence  \\\n",
       "0     51175   Actually, it is an old tradition of <b>distri...   \n",
       "1     36478  The graph given to us represents the informati...   \n",
       "2     67749   Moreover, they need money to feed their child...   \n",
       "3     30127   It is noticable that the figures in males <b>...   \n",
       "4      4238   Globalization creates an important basis for ...   \n",
       "...     ...                                                ...   \n",
       "1129  33536  The <b>project</b> is to create an automated v...   \n",
       "1130  68578   A more detailed look reveals that there are s...   \n",
       "1131  80835   Firstly, I believe that space could <b>wait</...   \n",
       "1132  67232   <b>Having paid</b> more attention to it we wi...   \n",
       "1133  36905   It is more comfortable of course when your fr...   \n",
       "\n",
       "                       Right answer_x           Error type_x  \\\n",
       "0                           spreading        lex_item_choice   \n",
       "1              the world's investment               Articles   \n",
       "2                          this money  Countable_uncountable   \n",
       "3                           who owned      Absence_comp_sent   \n",
       "4                                   ,             Derivation   \n",
       "...                               ...                    ...   \n",
       "1129  objective of the course project              Discourse   \n",
       "1130                    exceptions to             suggestion   \n",
       "1131                         wait for               Spelling   \n",
       "1132                        By paying                  Voice   \n",
       "1133                               at           Prepositions   \n",
       "\n",
       "                                              Corrected  \\\n",
       "0      Actually, it is an old tradition of spreading...   \n",
       "1     The graph given to us represents the informati...   \n",
       "2      Moreover, they need money to feed their child...   \n",
       "3      It is noticable that the figures in males who...   \n",
       "4      Globalization creates an important basis for ...   \n",
       "...                                                 ...   \n",
       "1129  The objective of the course project is to crea...   \n",
       "1130   A more detailed look reveals that there are s...   \n",
       "1131   Firstly, I believe that space could wait for ...   \n",
       "1132   By paying more attention to it we will decrea...   \n",
       "1133   It is more comfortable of course when your fr...   \n",
       "\n",
       "                       Right answer_y           Error type_y  \\\n",
       "0                           spreading        lex_item_choice   \n",
       "1              the world's investment               Articles   \n",
       "2                          this money  Countable_uncountable   \n",
       "3                           who owned                  Verbs   \n",
       "4                                   ,            Punctuation   \n",
       "...                               ...                    ...   \n",
       "1129  objective of the course project              Discourse   \n",
       "1130                    exceptions to             suggestion   \n",
       "1131                         wait for           Prepositions   \n",
       "1132                        By paying     Participial_constr   \n",
       "1133                               at           Prepositions   \n",
       "\n",
       "                                                 Folder        Filename  \\\n",
       "0     downloaded_2021_08_05_15_05_02099641/data/exam...   2017_ABl_48_2   \n",
       "1     downloaded_2021_08_05_15_05_02099641/data/exam...  2016_JSl_148_1   \n",
       "2     downloaded_2021_08_05_15_05_02099641/data/exam...  2017_EGe_113_2   \n",
       "3     downloaded_2021_08_05_15_05_02099641/data/old_...        ESha_2_1   \n",
       "4     downloaded_2021_08_05_15_05_02099641/data/2012...       esl_01275   \n",
       "...                                                 ...             ...   \n",
       "1129  downloaded_2021_08_05_15_05_02099641/data/2012...       esl_00372   \n",
       "1130  downloaded_2021_08_05_15_05_02099641/data/exam...  2017_EGe_167_1   \n",
       "1131  downloaded_2021_08_05_15_05_02099641/data/exam...  2017_EGe_203_2   \n",
       "1132  downloaded_2021_08_05_15_05_02099641/data/exam...   2017_EGe_86_2   \n",
       "1133  downloaded_2021_08_05_15_05_02099641/data/2012...       esl_00433   \n",
       "\n",
       "      Есть дубликат в exam  Есть дубликат  \n",
       "0                    False          False  \n",
       "1                    False          False  \n",
       "2                    False          False  \n",
       "3                    False          False  \n",
       "4                    False          False  \n",
       "...                    ...            ...  \n",
       "1129                 False          False  \n",
       "1130                 False          False  \n",
       "1131                 False          False  \n",
       "1132                 False          False  \n",
       "1133                 False          False  \n",
       "\n",
       "[844 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method drop in module pandas.core.frame:\n",
      "\n",
      "drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise') method of pandas.core.frame.DataFrame instance\n",
      "    Drop specified labels from rows or columns.\n",
      "    \n",
      "    Remove rows or columns by specifying label names and corresponding\n",
      "    axis, or by specifying directly index or column names. When using a\n",
      "    multi-index, labels on different levels can be removed by specifying\n",
      "    the level.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    labels : single label or list-like\n",
      "        Index or column labels to drop.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Whether to drop labels from the index (0 or 'index') or\n",
      "        columns (1 or 'columns').\n",
      "    index : single label or list-like\n",
      "        Alternative to specifying axis (``labels, axis=0``\n",
      "        is equivalent to ``index=labels``).\n",
      "    columns : single label or list-like\n",
      "        Alternative to specifying axis (``labels, axis=1``\n",
      "        is equivalent to ``columns=labels``).\n",
      "    level : int or level name, optional\n",
      "        For MultiIndex, level from which the labels will be removed.\n",
      "    inplace : bool, default False\n",
      "        If False, return a copy. Otherwise, do operation\n",
      "        inplace and return None.\n",
      "    errors : {'ignore', 'raise'}, default 'raise'\n",
      "        If 'ignore', suppress error and only existing labels are\n",
      "        dropped.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        DataFrame without the removed index or column labels.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    KeyError\n",
      "        If any of the labels is not found in the selected axis.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.loc : Label-location based indexer for selection by label.\n",
      "    DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      "        where (all or any) data are missing.\n",
      "    DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      "        removed, optionally only considering certain columns.\n",
      "    Series.drop : Return Series with specified index labels removed.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      "    ...                   columns=['A', 'B', 'C', 'D'])\n",
      "    >>> df\n",
      "       A  B   C   D\n",
      "    0  0  1   2   3\n",
      "    1  4  5   6   7\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns\n",
      "    \n",
      "    >>> df.drop(['B', 'C'], axis=1)\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    >>> df.drop(columns=['B', 'C'])\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    Drop a row by index\n",
      "    \n",
      "    >>> df.drop([0, 1])\n",
      "       A  B   C   D\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns and/or rows of MultiIndex DataFrame\n",
      "    \n",
      "    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      "    ...                              ['speed', 'weight', 'length']],\n",
      "    ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      "    ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      "    >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      "    ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      "    ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      "    ...                         [1, 0.8], [0.3, 0.2]])\n",
      "    >>> df\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "            length  1.5     1.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "            length  1.5     0.8\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "            length  0.3     0.2\n",
      "    \n",
      "    >>> df.drop(index='cow', columns='small')\n",
      "                    big\n",
      "    lama    speed   45.0\n",
      "            weight  200.0\n",
      "            length  1.5\n",
      "    falcon  speed   320.0\n",
      "            weight  1.0\n",
      "            length  0.3\n",
      "    \n",
      "    >>> df.drop(index='length', level=1)\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df_concat.drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_excel(\"realec_sample_concat.xlsx\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method merge in module pandas.core.frame:\n",
      "\n",
      "merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) -> 'DataFrame' method of pandas.core.frame.DataFrame instance\n",
      "    Merge DataFrame or named Series objects with a database-style join.\n",
      "    \n",
      "    The join is done on columns or indexes. If joining columns on\n",
      "    columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      "    on indexes or indexes on a column or columns, the index will be passed on.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    right : DataFrame or named Series\n",
      "        Object to merge with.\n",
      "    how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      "        Type of merge to be performed.\n",
      "    \n",
      "        * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "          preserve key order.\n",
      "        * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "          preserve key order.\n",
      "        * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "          join; sort keys lexicographically.\n",
      "        * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "          join; preserve the order of the left keys.\n",
      "    on : label or list\n",
      "        Column or index level names to join on. These must be found in both\n",
      "        DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      "        to the intersection of the columns in both DataFrames.\n",
      "    left_on : label or list, or array-like\n",
      "        Column or index level names to join on in the left DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the left DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    right_on : label or list, or array-like\n",
      "        Column or index level names to join on in the right DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the right DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    left_index : bool, default False\n",
      "        Use the index from the left DataFrame as the join key(s). If it is a\n",
      "        MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "        or a number of columns) must match the number of levels.\n",
      "    right_index : bool, default False\n",
      "        Use the index from the right DataFrame as the join key. Same caveats as\n",
      "        left_index.\n",
      "    sort : bool, default False\n",
      "        Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "        the order of the join keys depends on the join type (how keyword).\n",
      "    suffixes : list-like, default is (\"_x\", \"_y\")\n",
      "        A length-2 sequence where each element is optionally a string\n",
      "        indicating the suffix to add to overlapping column names in\n",
      "        `left` and `right` respectively. Pass a value of `None` instead\n",
      "        of a string to indicate that the column name from `left` or\n",
      "        `right` should be left as-is, with no suffix. At least one of the\n",
      "        values must not be None.\n",
      "    copy : bool, default True\n",
      "        If False, avoid copy if possible.\n",
      "    indicator : bool or str, default False\n",
      "        If True, adds a column to the output DataFrame called \"_merge\" with\n",
      "        information on the source of each row. The column can be given a different\n",
      "        name by providing a string argument. The column will have a Categorical\n",
      "        type with the value of \"left_only\" for observations whose merge key only\n",
      "        appears in the left DataFrame, \"right_only\" for observations\n",
      "        whose merge key only appears in the right DataFrame, and \"both\"\n",
      "        if the observation's merge key is found in both DataFrames.\n",
      "    \n",
      "    validate : str, optional\n",
      "        If specified, checks if merge is of specified type.\n",
      "    \n",
      "        * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "          left and right datasets.\n",
      "        * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "          dataset.\n",
      "        * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "          dataset.\n",
      "        * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        A DataFrame of the two merged objects.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    merge_ordered : Merge with optional filling/interpolation.\n",
      "    merge_asof : Merge on nearest keys.\n",
      "    DataFrame.join : Similar method using indices.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Support for specifying index levels as the `on`, `left_on`, and\n",
      "    `right_on` parameters was added in version 0.23.0\n",
      "    Support for merging named Series objects was added in version 0.24.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [1, 2, 3, 5]})\n",
      "    >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [5, 6, 7, 8]})\n",
      "    >>> df1\n",
      "        lkey value\n",
      "    0   foo      1\n",
      "    1   bar      2\n",
      "    2   baz      3\n",
      "    3   foo      5\n",
      "    >>> df2\n",
      "        rkey value\n",
      "    0   foo      5\n",
      "    1   bar      6\n",
      "    2   baz      7\n",
      "    3   foo      8\n",
      "    \n",
      "    Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      "    the default suffixes, _x and _y, appended.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      "      lkey  value_x rkey  value_y\n",
      "    0  foo        1  foo        5\n",
      "    1  foo        1  foo        8\n",
      "    2  foo        5  foo        5\n",
      "    3  foo        5  foo        8\n",
      "    4  bar        2  bar        6\n",
      "    5  baz        3  baz        7\n",
      "    \n",
      "    Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      "    appended to any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      "    ...           suffixes=('_left', '_right'))\n",
      "      lkey  value_left rkey  value_right\n",
      "    0  foo           1  foo            5\n",
      "    1  foo           1  foo            8\n",
      "    2  foo           5  foo            5\n",
      "    3  foo           5  foo            8\n",
      "    4  bar           2  bar            6\n",
      "    5  baz           3  baz            7\n",
      "    \n",
      "    Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      "    any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: columns overlap but no suffix specified:\n",
      "        Index(['value'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df1.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
